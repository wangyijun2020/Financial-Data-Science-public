{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.2 MLE for Gaussian AR(1)-GARCH(1,1)\n",
    "\n",
    "Fit a Gaussian AR(1)-GARCH(1,1) to the 10-year government bond yield. Use the following procedure:\n",
    "\n",
    "1. Write a function, called \"garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, epsilon)\". It takes the parameters of the variance equation as an input as well as the residuals of the mean equation. The function returns the GARCH(1,1) implied variance. Note, the first variance is computed using \"epsilon[0]\" and the start value of the variance, i.e. \"sigma2_1\". \n",
    "\n",
    "2. Write a second function, called, \"Neg_loglikelihood_ar1_Garch11(parameters)\". It takes the model parameters as input and returns the negative joint log likelihood function. \n",
    "\n",
    "3. Use smart starting values for the optimization (from last week's Python for Financial Data Science material, see below). In addition, we use rather uninformative starting values for beta and sigma2_1, namely 0.01 and 1, respectively. **Praktomat: estimated parameters from local unconstrained optimization**\n",
    "\n",
    "4. You want to use a bounded optimizer to ensure the estimate imply: (i) stationary interest rates (stationary mean equation), (ii) positive unconditional interest rates, (iii) stationary variance of interest rates (stationary variance equation), (iv) positive unconditional variance of interest rate. **Type of optimizer: differential_evolution**. **Praktomat: estimated parameter global constrained optimization**\n",
    "\n",
    "5. Hand-in the mathematical algorithm and pseudo code that underlines your Python implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1954-04-01    2.29\n",
       "1954-05-01    2.37\n",
       "1954-06-01    2.38\n",
       "1954-07-01    2.30\n",
       "1954-08-01    2.36\n",
       "              ... \n",
       "2005-12-01    4.47\n",
       "2006-01-01    4.42\n",
       "2006-02-01    4.57\n",
       "2006-03-01    4.72\n",
       "2006-04-01    4.99\n",
       "Name: 120, Length: 625, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.read_excel(\"GovBondYields.xls\", index_col = [0])\n",
    "y10_df= y_df[120]\n",
    "y10_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=len(y_df)\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LL**\n",
    "\n",
    "$$\n",
    "L_T(\\phi_0, \\phi_1, \\alpha_0, \\alpha_1, \\beta_1, \\sigma_1) = \\prod_{t=2}^T \\frac{1}{\\sqrt{ 2 \\pi (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1})}} \\times \\exp\\left( -\\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \\right)\n",
    "$$\n",
    "\n",
    "with $\\sigma^2_t = \\alpha_0 + \\alpha_1 \\epsilon^2_{t-1} + \\beta_1 \\sigma^2_{t-1}, s.t. \\sigma^2_1 = \\text{known parameter}$\n",
    "\n",
    "Note:\n",
    " $$\n",
    " \\ln (L_T(.)) = \\sum_{t=2}^T -\\frac{1}{2} \\ln(2\\pi [\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1}]) -  \\frac{(r_t - [\\phi_0 + \\phi_1 r_{t-1}])^2}{2 (\\alpha_0 + \\alpha_1 \\epsilon^2_{t-1}+ \\beta_1 \\sigma^2_{t-1})} \n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**function GARCH_11_VARIANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, epsilon):\n",
    "    sigma_square= np.zeros(623)\n",
    "    sigma_square[0]= alpha_0 + alpha_1*epsilon[0]**2+ beta_1*sigma2_1\n",
    "    for i in range(1,623):\n",
    "        sigma_square[i]= alpha_0 + alpha_1*epsilon[i]**2+ beta_1*sigma_square[i-1]\n",
    "    \n",
    "    return sigma_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-ln(L_T)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Neg_loglikelihood_ar1_Garch11(parameters,r_t):\n",
    "    phi_0   = parameters[0]\n",
    "    phi_1   = parameters[1]\n",
    "    alpha_0 = parameters[2]\n",
    "    alpha_1 = parameters[3]\n",
    "    beta_1  = parameters[4]\n",
    "    sigma2_1 = parameters[5]\n",
    "\n",
    "    means = phi_0 + phi_1 * r_t.iloc[:-1].values\n",
    "    eps   = r_t.iloc[1:].values - means\n",
    "    vars_  =  garch11_variance(alpha_0, alpha_1, beta_1, sigma2_1, eps[:-1])\n",
    "       \n",
    "    loglikeli = np.sum(-0.5 * np.log(2 * np.pi * vars_) - 0.5*(eps[1:])**2/(vars_))\n",
    "    \n",
    "    return -loglikeli\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start Values from 2pass Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start values for AR(1)-GARCH(1,1) parameters from last week's Python for Financial Data Science material\n",
    "phi0_start = 0.0204\n",
    "phi1_start = 0.9962\n",
    "alpha0_start = 0.0004\n",
    "alpha1_start = 0.3157\n",
    "#uninformative start values for GARCH part\n",
    "beta1_start = 0.01\n",
    "sigma2_1_start = 1\n",
    "\n",
    "ar1_garch11_params_start = [phi0_start, phi1_start, alpha0_start, alpha1_start, beta1_start, sigma2_1_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4290.227857000036"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neg_loglikelihood_ar1_Garch11(ar1_garch11_params_start, y10_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unconstrained Optimization: Nelder-Mead Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-8ae57d30baeb>:13: RuntimeWarning: invalid value encountered in log\n",
      "  loglikeli = np.sum(-0.5 * np.log(2 * np.pi * vars_) - 0.5*(eps[1:])**2/(vars_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 166.840529\n",
      "         Iterations: 651\n",
      "         Function evaluations: 1042\n"
     ]
    }
   ],
   "source": [
    "#min (-ln L_T)\n",
    "import scipy.optimize as sco\n",
    "\n",
    "#Non-Constrained, non-linear optimization, i.e. https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html\n",
    "ar1_arch1_params_optimal = sco.minimize(Neg_loglikelihood_ar1_Garch11, ar1_garch11_params_start, args=(y10_df,),\n",
    "                                        method='Nelder-Mead', options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[-9.40566161e-02,  1.02268374e+00,  6.73421893e-03,\n",
       "         4.44696040e+00,  3.77398370e-03, -1.90019306e+01],\n",
       "       [-9.40560653e-02,  1.02268361e+00,  6.73422438e-03,\n",
       "         4.44696609e+00,  3.77396721e-03, -1.90019887e+01],\n",
       "       [-9.40568899e-02,  1.02268378e+00,  6.73420528e-03,\n",
       "         4.44695007e+00,  3.77400414e-03, -1.90018556e+01],\n",
       "       [-9.40567120e-02,  1.02268375e+00,  6.73423164e-03,\n",
       "         4.44696873e+00,  3.77398900e-03, -1.90019790e+01],\n",
       "       [-9.40562154e-02,  1.02268363e+00,  6.73420848e-03,\n",
       "         4.44695465e+00,  3.77398253e-03, -1.90019117e+01],\n",
       "       [-9.40562086e-02,  1.02268371e+00,  6.73421511e-03,\n",
       "         4.44695911e+00,  3.77396584e-03, -1.90019394e+01],\n",
       "       [-9.40566746e-02,  1.02268374e+00,  6.73419686e-03,\n",
       "         4.44694515e+00,  3.77399460e-03, -1.90018332e+01]]), array([166.84052934, 166.84052934, 166.84052934, 166.84052934,\n",
       "       166.84052934, 166.84052935, 166.84052935]))\n",
       "           fun: 166.84052933771687\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 1042\n",
       "           nit: 651\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([-9.40566161e-02,  1.02268374e+00,  6.73421893e-03,  4.44696040e+00,\n",
       "        3.77398370e-03, -1.90019306e+01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1_arch1_params_optimal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stationary GARCH(1,1)** Stationary Conditions and Positivity Restrictions for the Variance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary mean equation:\n",
    "$$\n",
    "|\\phi_1| < 1\n",
    "$$\n",
    "\n",
    "Stationary variance equation:\n",
    "$$\n",
    "\\alpha_1 + \\beta_1 < 1\n",
    "$$\n",
    "\n",
    "Positive unconditional variance forecast:\n",
    "$$\n",
    "\\alpha_0 > 0 \\qquad \\text{and} \\qquad \\alpha_1, \\beta_1, \\sigma^2_{1} \\in \\mathcal{R}_+\n",
    "$$\n",
    "\n",
    "Positive unconditional interest rates:\n",
    "$$\n",
    "\\phi_0 > 0, \\qquad \\phi_1 > 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bounded Optimization:** \n",
    "\n",
    "Hints:\n",
    "\n",
    "1. Please specify the bounds for all the parameters. Please use 1 for all the upper bounds.\n",
    "\n",
    "2. For inequality constraints please following the doc from scipy in the following link:\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.differential_evolution.html. In addition, for $ \\alpha_1 + \\beta_1 < 1$ we specify it as $ 0<\\alpha_1 + \\beta_1 < 1$. \n",
    "\n",
    "3. Please use seed=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " from scipy.optimize import NonlinearConstraint, differential_evolution, Bounds\n",
    "   \n",
    " def constr_f(parameters):\n",
    "        return np.array(parameters[3] + parameters[4])\n",
    "    \n",
    "\n",
    "nlc = NonlinearConstraint(constr_f, 0, 1)\n",
    "    # (0,1)(0,1)(0,1)(0,1)(0,1)(0,1)\n",
    "bound= Bounds(lb=[0,0,0,0,0,0], ub=[1,1,1,1,1,1])\n",
    "    \n",
    "bound_opt= differential_evolution(func=Neg_loglikelihood_ar1_Garch11, bounds=bound,args=(y10_df,),constraints=(nlc), seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           constr: [array([0.])]\n",
       " constr_violation: 0.0\n",
       "              fun: -76.80268667513437\n",
       "              jac: [array([[0., 0., 0., 1., 1., 0.]]), array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])]\n",
       "            maxcv: 0.0\n",
       "          message: 'Optimization terminated successfully.'\n",
       "             nfev: 7004\n",
       "              nit: 93\n",
       "          success: True\n",
       "                x: array([4.95223927e-02, 9.91773642e-01, 2.26752550e-04, 1.44879677e-01,\n",
       "       8.55120296e-01, 2.80554606e-03])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
